{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c95abb-8000-48a9-9c22-4a43d17607a7",
   "metadata": {},
   "source": [
    "### SHERLOCK EPISODE-1: IDENTITY FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613ca983-cafd-4907-872f-a79cd8941a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dlib\n",
    "import face_recognition\n",
    "import pliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea561261-954d-4d4e-adc0-97c4eef792b1",
   "metadata": {},
   "source": [
    "#### IMPORT VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4561c491-292d-46de-8c0d-1e155473f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get stimuli\n",
    "sherlock_video = 'stimuli_Sherlock.m4v'\n",
    "\n",
    "### read video into pliers\n",
    "from pliers.stimuli import VideoStim\n",
    "video = VideoStim(sherlock_video)\n",
    "\n",
    "### downsample video frames (1 frame/second)\n",
    "from pliers.filters import FrameSamplingFilter\n",
    "filt = FrameSamplingFilter(hertz=1)\n",
    "selected_frames = filt.transform(video)\n",
    "n_frames = selected_frames.n_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98d2d5-b7c9-44c5-a24f-4aa6c0214921",
   "metadata": {},
   "source": [
    "#### GET TIME SERIES OF FACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c42100-c9f6-40a7-9f2b-c2ee3b4caf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pliers.extractors import FaceRecognitionFaceLocationsExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dea9e7-705d-4ca4-9cb0-98f403cdab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stim: 317it [15:35,  2.88s/it]"
     ]
    }
   ],
   "source": [
    "# specify convolutional neural network extractor\n",
    "# from pliers.extractors import FaceRecognitionFaceLocationsExtractor\n",
    "face_ext = FaceRecognitionFaceLocationsExtractor(model='cnn')\n",
    "\n",
    "# detect faces in selected frames\n",
    "face_features = face_ext.transform(selected_frames)\n",
    "\n",
    "from pliers.extractors import merge_results\n",
    "merged_faces = merge_results(face_features, metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211b08d-bd2d-4eae-bc57-4c981ae319e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which frames have faces in them\n",
    "face_frames = [f.data for f in selected_frames if f.onset in merged_faces.onset.tolist()]\n",
    "nonface_frames = [f.data for f in selected_frames if f.onset not in merged_faces.onset.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb33a3-2105-48e0-8bb8-91b152cb8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot frames\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "def plot_img_grid(img_list, shape, figsize=(30., 30.)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.1)\n",
    "\n",
    "    for ax, im in zip(grid, img_list):\n",
    "        ax.imshow(im)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca408745-7573-4124-b775-b9117dc500bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_grid(face_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791f7d7-1f5f-468d-a4ae-79bde31c6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_grid(nonface_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cee276-dd27-49d4-a943-b681e657cba7",
   "metadata": {},
   "source": [
    "#### CREATE AND SAVE PNGS OF EACH FACE FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14becbd-53ea-400d-b497-a3ca34684c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get face time stamps\n",
    "\n",
    "### save face images into folder\n",
    "\n",
    "### use face location data to cut image of face and save???\n",
    "\n",
    "### deepface to identify individuals\n",
    "from deepface import DeepFace\n",
    "result = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332112b-290c-444e-8160-fe45650aa7c8",
   "metadata": {},
   "source": [
    "#### USE DEEP FACE TO COMPARE INDIVIDUALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36ddde-71da-4f44-8c40-6bf62c43263e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7647222-67fe-4487-b01b-766911dd8f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
